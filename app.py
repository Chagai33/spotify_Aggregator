import streamlit as st
import pandas as pd
import re
import time
import unicodedata
import spotipy
from spotipy.oauth2 import SpotifyOAuth
from dotenv import load_dotenv

# Load environment variables (Client ID, Secret, Redirect URI)
load_dotenv()

# --- Configuration Definitions ---
TARGET_PLAYLISTS = {
    "Israeli Hip Hop": "1Ycl9i5uMtniDKs0jKvJOe",
    "Reggae": "3obWJRscGGN4QvmeLZK7US",
    "Israeli Music": "70y6Euzv1eUaYgR6Qzoo2r",
    "Country, Indie": "6QZz84AaYPlD1ALgrVacP4",
    "Melodic House": "7F8Bea5phhXrDwAx5rETPg",
    "Hip Hop, Rap": "3GiWLHwdkZU9VQ4i1aagWa",
    "Afrobeats": "1XyXp1FRHBRnvxmmhT5Sz6",
    "Mizrahi": "1zcEZURYYKMCvs4rpTB6ti",
    "Reggaeton": "09QZH7Nlj4vS9Paur6Srcm"
}

GENRE_ROUTING_DICT = {
    "Israeli Hip Hop": ["Israeli Hip Hop", "Israeli Rap"],
    "Reggae": ["Reggae", "Modern Reggae", "Reggae Rock", "Indie Reggae", "West Coast Reggae"],
    "Israeli Music": ["Israeli Music", "Israeli Pop", "Israeli Indie", "Indie IL"],
    "Country, Indie": ["Country", "Country Pop", "Indie", "Indie Pop", "American Indie", "Indie Folk", "Pop, Folk", "Folk, Pop", "Indie Soul", "Soul Indie", "Retro soul", "Modern Indie Folk", "Modern Indie", "Indie Rock", "Alternative Indie", "Alternative Pop", "Acoustic Soul", "Folk Acoustic", "Folk-Soul", "Pop Soul", "Lo-Fi", "R And B", "Rendb", "RB", "Meditation", "Chill Indie", "Spacial Intro", "Electro Chil", "Indie Modern Funk"],
    "Melodic House": ["Melodic House", "Melodic Techno", "Tropical House", "Organic House", "Indie House", "Tech House", "Techno House", "Bass House", "Base House", "Funky Bass House", "Edm", "EDM House", "Electro House", "Funky House", "Fusion House", "Electropop", "Brazilian Edm", "Mix House", "Groove House", "House", "Mix Gener", "Mix", "Groove Metal"],
    "Hip Hop, Rap": ["Hip Hop", "Rap", "Hip Hop, Rap", "Rap, Hip Hop", "UG Hip Hop", "Underground Hip Hop", "UG Hip Pop", "Trap", "Dark Trap", "Latin Trap", "Bass Trap", "Hip Pop", "East Coast Hip Hop", "Multigenre Rap", "Dfw Rap", "London Rap", "Westcoast Rap", "West Coast Rap", "Drift Phonk", "Hip Hop Rap", "Hip Pop / Trap"],
    "Afrobeats": ["Afrobeats", "Afrobeat", "Dancehall", "Kenyan Drill"],
    "Mizrahi": ["Mizrahi", "Mizrachi", "Yemeni Diwan"],
    "Reggaeton": ["Reggaeton", "Reggaton"]
}

# --- Parallel Routing Configuration ---
RAW_ISRAELI_ARTISTS = [
    "2t", "ACCULBED", "Adam Ten (××“× ×˜×Ÿ)", "ASHER SWISSA (×¡×§××–×™)", "Asal (××¡×œ)", "ATAR MAYNER (×¢×˜×¨ ××™×™× ×¨)", "BÄ˜ÃƒTFÃ“Ã˜T (×‘×™×˜×¤×•×˜)", "BLNKY", "DE SOFFER (×“×™ ×¡×•×¤×¨)", "E-Z (××™×–×™)", "ECHO (××§×•)", "EVILEAF", "Folly Tree (×¤×•×œ×™ ×˜×¨×™)", "Full Trunk (×¤×•×œ ×˜×¨×× ×§)", "Garden City Movement", "iogi (×™×•×’×‘ ×’×œ×•×¡××Ÿ)", "iRO", "ILANZE", "Jacob (IL)", "JAMAA (×’'×××¢)", "JETFIRE (×’'×˜×¤×™×™×¨)", "JIGI", "Kiki Malinki (×§×™×§×™ ××œ×™× ×§×™)", "Kintsugi (×§×™× ×¦×•×’×™)", "KLIN SADYLE (×§×œ×™×Ÿ ×¡×“×™×™×œ)", "Koevary (×§×•×‘××¨×™)", "Lava Dome", "Mita Gami (××™×˜×” ×’×××™)", "N-47", "OMRI. (×¢×•××¨×™.)", "PA'AM (×¤×¢×)", "REGINI", "ROMI (×¨×•××™)", "ROUSSO (×¨×•×¡×•)", "Saxtracks", "SHIRU (×©×™×¨×•)", "Soft Deep (×¡×•×¤×˜ ×“×™×¤)", "Stargo (×¡×˜××¨×’×•)", "Sync (×¡×™× ×§)", "The White Screen (×”××¡×š ×”×œ×‘×Ÿ)", "Vulkan (×•×•×œ×§×Ÿ)", "YOYO (×™×•×™×•)", "××‘×™ ××‘×•×¨×•××™", "××‘×™×‘ ×‘×›×¨", "××‘×™×”×• ×¤× ×—×¡×•×‘ (××•×¢×“×•×Ÿ ×”×§×¦×‘ ×©×œ ××‘×™×”×• ×¤× ×—×¡×•×‘)", "××‘×™×—×™ × ×¤×ª×œ×™", "××‘×™×ª×¨ ×©××—×™", "××‘× ×¨ ×˜×•××’", "××‘×¨×”× ××™×™×œ××•", "××‘×¨×”× ×œ×’×¡×”", "××‘×¨×™ ×’'×™", "××’× ×‘×•×—×‘×•×˜", "××“×", "××“×™×¨ ×’×¥", "××•×“×™×”", "××•×“×™××Ÿ (Hoodyman)", "××•×¤×™×¨ ××œ×•×œ", "××•×¤×§ ××“× ×§", "××•×¤×§ × ×—××Ÿ", "××•×¨××œ (Orel)", "××•×¨×™ ×¡×‘××Ÿ", "××•×¨×™ ×©×•×—×˜", "××•×¨×™×ª ×˜×©×•××”", "××•×¨×˜×’×”", "××•×¨×Ÿ ×‘×¨×–×™×œ×™", "××™×–×™ (E-Z)", "××™×¦×™×§ ×©××œ×™", "××™×ª×™ ×’×œ (Itai Gal)", "××™×ª×™ ×’×œ×• (Itay Galo)", "××™×ª×™ ×œ×•×™", "××™×ª××¨ ×™× ×™×‘", "××™×ª××¨ ×¤×™×©", "××œ×“×“ ×¦×™×˜×¨×™×Ÿ", "××œ×•× ×” ×˜×œ", "××œ×™ ×—×•×œ×™", "××œ×™××•×¨ ×©××©", "××œ×™×¢×“", "××œ×™×¢×–×¨", "××œ×××œ×™×› (Almalik)", "××œ××•×’ ×’×•×–×œ×Ÿ", "×××™×¨ ×‘× ×™×•×Ÿ", "×××™×¨ ×©×“×”", "×××¡×œ×", "×× ×” ×–×§", "×× ×“×¨×“×•×’ (Underdogg)", "×× ×™×¡ × ×§×©", "××¡×§×¨ (ASKER)", "××¨×– ×œ×‘ ××¨×™", "××¨×™××œ×” ×‘×¨×•×š", "××©×›× ×– (Ashken)", "××ª×œ (Ethel)", "×‘××œ×™×©×’", "×‘×•× ×¤×", "×‘×•×¡×§×™×œ×– (Booskills)", "×‘×™×’ ×’'×™×™ (Big-J)", "×‘×™×’ ×¡×™×–×• (Big Sezo)", "×‘×œ ×“×•×¨×•×Ÿ", "×‘×Ÿ ××œ ×ª×‘×•×¨×™", "×‘×Ÿ ××™×¨×Ÿ", "×‘× ××œ×™ (Beneli)", "×‘×¨ ××œ×¤× ×“×¨×™", "×‘×¨××“×•×Ÿ (Bar Adon)", "×‘×¨×™ ×¡×—×¨×•×£", "×‘×ª××œ ×¡×‘×—", "×‘×ª×™××œ ×¡×™×¡××™", "×’'×™×™×Ÿ ×‘×•×¨×“×•", "×’'× ×™ ×¤× ×§×™×Ÿ", "×’×™× ××•×–×¡", "×’×™× × ×•×™××Ÿ (Guy newman)", "×’×™× ×•×™×”×œ", "×’×™××’×™×", "×’×œ ××“×", "×’×œ×“×™ (Galdi)", "×’×œ×¢×“ ×›×”× ×", "×’×•×Ÿ ×‘×Ÿ ××¨×™", "×’×•×¨×œ×™×§ (Gorlik)", "×’×™×œ×™ ××¡×¨×£", "×“×•×“ ×“'××•×¨", "×“×•×“ ×œ×‘ ××¨×™", "×“×•×“ ××¢×™×™×Ÿ", "×“×•×“ ×‘×Ÿ ××¨×–×”", "×“×•×“×", "×“×•×“×• ×¤××¨×•×§", "×“×•×Ÿ ×’'×•×–×£ (Dawn Joseph.)", "×“×•×¨×•×Ÿ ××–×•×œ××™", "×“×™××” XR", "×“×™× ×’'××Ÿ", "×“×Ÿ ×–×™×ª×•×Ÿ", "×“× ×™××œ ×‘×¨×–×™×œ××™", "×“× ×™××œ ×—×Ÿ", "×“× ×™××œ ×¨×•×‘×™×Ÿ", "×“×•×ª×Ÿ ×¡×™×˜×‘×•×Ÿ", "×”×“×¨ ×”×œ×œ", "×”×™×•×¦×¨×™×", "×”×™×œ×” ×¤××¨", "×”×™×œ×” ×¨×•×—", "×”×¦×œ", "×”×ª××•××™× (Twins DJ's)", "×”×ª×§×•×•×” 6", "×”××©×§×¤×™×™× ×©×œ × ×•×™×¤×œ×“", "×•×•×œ×§×Ÿ (Vulkan)", "×•×™×•×• (Vivo)", "×•×™×™×–×™ (Vaizi)", "×•×™×§ ××•×—× ×” ×–'××Ÿ", "×–×”×‘×™ (Zehavi)", "×–×™×•", "×–×œ×™×’", "×—×™×™× ××•×œ×™××œ", "×—×™×™× ××©×”", "×—×™×™××ª×™ (Haya Avichar)", "×—×Ÿ ×¤×•×¨×ª×™", "×—× ×™ ××¡×œ×”", "×—×¡×Ÿ MC", "×˜×”×¨", "×˜×•×›×˜×™ (Tochti)", "×˜×•× ×”", "×˜×œ ×›×¨××™", "×˜×œ×™×¡×××Ÿ", "×˜×•×§×¡×™×§×• (Toxico)", "×ª×•× ×’×¤×Ÿ", "×ª×•××¨ ×•×¨×¡×¦'×”", "×ª×•××¨ ×™×•×¡×£", "×ª×•××¨ ×™×©×¢×™×”×•", "×™× × ×” (Ya-Ne)", "×™×•××‘ ×œ×¤×™×“", "×™×•× ×™ ×‘×œ×•×š", "×™×•× ×™ ×“×•×™×˜×©", "×™×•× ×ª×Ÿ ×§×œ×™××™", "×™×•×¡×™ ×©×˜×¨×™×ª", "×™×•×©×™", "×™×¢×œ ×›×”×Ÿ", "×™×¤×¢×ª ×‘×¨ ×¡×œ×¢", "×™×¤×¢×ª × ×˜×•×‘×™×¥", "×™×¨×™×Ÿ ×¤×¨×™××§", "×™×©×™ ×¨×™×‘×•", "×›×”×Ÿ", "×›×œ×™×¤×™ (Kalifi)", "×›×¤×™×¨ ×¢×–×¨×Ÿ", "×›×¨×§×•×§×œ×™", "×œ××” ×©×‘×ª", "×œ×•×¨×Ÿ ×¤×œ×“", "×œ×™××•×¨ × ×¨×§×™×¡", "×œ×™×¢×“ ×××™×¨", "×œ×™×¢× ×—×›××•×Ÿ", "×œ×™×¨×•×Ÿ ×¢××¨×", "×œ×™×¨ (LIR)", "×œ×¨×•×– (Laroz)", "×××™ ×•×™×¦××Ÿ", "×××™ ×˜×•×•×™×§", "×××•×¨ ××“×¨×™", "×××•×¨ ××œ×•×©", "×××•×¨ ××©×›× ×–×™", "×××™×” ×‘×•×¡×§×™×œ×”", "××•×©×™×§×• ××•×¨", "××•×¨", "××•×¨×Ÿ ××–×•×¨", "××™×›××œ ×¨×¤××œ", "××™×›×œ ×–× ×“× ×™", "××™×§×“×• (Mikado)", "××™×§×” ×“×•××¨×™", "××™×§×” ××œ×˜××Ÿ!", "××™×§×™ (Miki)", "××™×© ×‘×–'×¨× ×•", "××™×¨×‘ ×”×œ×™× ×’×¨", "××™×¡×˜×¨××™×¡ (Mistermiss)", "××§ ×¤×™×˜×•×¡×™ (Mc fitusi)", "× ×•×’×” ××¨×–", "× ×•×™ ×¤×“×œ×•×Ÿ", "× ×•×™×” ××•×–×Ÿ", "× ×•×™××Ÿ", "× ×•×¢×” ×§×™×¨×œ", "× ×•×¢×” ×©××•××˜", "× ×•×¤×¨ ×¡×œ×××Ÿ", "× ×˜×•×¨×œ (Natural)", "× ×™× ×” ×§×œ×•×¨", "× ×™×¦×Ÿ ××™×–× ×‘×¨×’", "× ××©", "× ×¨×§×™×¡", "× ×¡×¨×™×Ÿ ×§×“×¨×™", "× ×ª×œ×™", "×¡××‘×œ×™××™× ×œ", "×¡×‘×¡×˜×™××Ÿ XL", "×¡×’×•×œ 59", "×¡×•×œ ×¡×¤×©×™××œ (Soul Special)", "×¡×•×œ×˜×™ (Salty)", "×¡×™×“×™ (Sidi)", "×¡×™×•×•×Ÿ", "×¡×™×•×Ÿ ×˜×œ××•×¨", "×¡×™××” × ×•×Ÿ", "×¡×œ×™× ×¤×™× (Slimfim)", "×¡×¤×™×¨ ×¡×‘×Ÿ", "×¡×˜×˜×™×§", "×¡×˜×¤×Ÿ ×œ×’×¨", "×¢×‘×¨×™ ×œ×™×“×¨", "×¢×“×Ÿ ×‘×Ÿ ×–×§×Ÿ", "×¢×“×Ÿ ×“×¨×¡×•", "×¢×“×Ÿ ×—×¡×•×Ÿ", "×¢×“×Ÿ ×××™×¨×™", "×¢×•××¨ ××“×", "×¢×•××¨ ××•×©×§×•×‘×™×¥", "×¢×•××¨ × ×¦×¨", "×¢×•××¨×™ ×¤×™×œ×¡", "×¢×•××¨×™ 69 ×¡×’×œ", "×¢×•××¨×™ ×¡×‘×—", "×¢×™×“×• ×‘×Ÿ ×“×‘", "×¢×™×“×• ×‘×™ (Ido B)", "×¢×™×“×• ××™××•×Ÿ", "×¢×™×“×Ÿ ×—×‘×™×‘ (×¢×™×“×Ÿ ×¨×¤××œ ×—×‘×™×‘)", "×¢×™×“×Ÿ ×¦'××•", "×¢×™×“×Ÿ ×¨×™×™×›×œ", "×¢×™×œ×™ ×‘×•×˜× ×¨", "×¢×œ××” ×’×•×‘", "×¢××™×¨ ×‘× ×™×•×Ÿ", "×¢× ×‘×œ ×¨×–", "×¢× ×‘×¨", "×¢×¨×Ÿ ×™×•×¡×£", "×¢×¨×Ÿ ×¦×•×¨", "×¤××¡ (Fass)", "×¤×˜×¨×™×§ ×¡×‘×’", "×¤×œ×“", "×¦×’××™ ×‘×•×™", "×¦×•×§×•×©", "×¦×™×•×Ÿ ×‘×¨×•×š", "×¦×™×•×Ÿ ×’×•×œ×Ÿ", "×¦×œ×™×œ ×“× ×™×Ÿ", "×¦×¤×¨×™×¨", "×§××¤×—", "×§×•×‘×™ ×¤×¨×¥", "×§×•×¨×œ ×‘×™×¡××•×˜", "×§×•×ª×™×××Ÿ", "×§×¨××–×œ (Karmazel)", "×¨×‘×™×“ ×¤×œ×•×˜× ×™×§", "×¨×‘×™×‘ ×›× ×¨", "×¨×•××™ ××“×", "×¨×•×‘×™ ×¤××™×™×¨ (Roby Fayer)", "×¨×•×Ÿ ×‘×•×—× ×™×§", "×¨×•×Ÿ ×‘×™ (Ron B)", "×¨×•×Ÿ ×—×™×•×Ÿ", "×¨×•×Ÿ ×›×”×Ÿ", "×¨×•×Ÿ × ×©×¨", "×¨×•×Ÿ ×¤×¨×¥", "×¨×•×Ÿ ×¤×¨×˜×•×§ (ron.partuk)", "×¨×•× ×” ×§×™× ×Ÿ", "×¨×•× ×™ ×“×œ×•××™", "×¨×•× ×™ ×—×‘×¨", "×¨×•×¢×™ ×¨×™×§", "×¨×•×¢×™ ×¡× ×“×œ×¨", "×¨×•××Ÿ ×”×•×œ×§", "×¨×•×™ ×¡×•×¤×¨ (Royal Sopher)", "×¨×™×§×• (Rico)", "×¨×™×£ ×›×”×Ÿ", "×¨×•×ª× ×›×”×Ÿ", "×¨×•×ª× ×“×•×¨×•×Ÿ", "×¨×Ÿ ×“× ×§×¨", "×©××–××××˜", "×©×’×‘", "×©×’×™× ×“×”×Ÿ", "×©×—×¨ ×™×•×¡×£", "×©×—×¨ ×¡××•×œ", "×©×™ ×‘×œ× ×§×•", "×©×™ × ×—×™×™×¡×™", "×©×™ (Shae)", "×©×™×œ×” ××œ×™×”", "×©×™×¨×™ ××™××•×Ÿ", "×©×™×¨×•×˜×• (Shiroto)", "×©×™×¨ ×’×‘××™", "×©×™×¨ ×“×•×“ ×’×“×¡×™", "×©×™×¨×” ×‘×Ÿ ×©××—×•×Ÿ", "×©×™×¨×” ×–×œ×•×£", "×©×™×¨×” ××œ×›×”", "×©×™×¨×” ××•×¨", "×©×™×¨×ª ××¤×•× ×™×", "×©×™×¨×– ××‘×¨×”×", "×©×§×œ", "×©×œ×™ ××¨×¦'×¨", "×©×œ×™ ×¤×¨×œ", "×©×¨×™×™ ××“×¨", "×©×¨×§ (ShrekDiMC)", "×©×¨×™×ª ×—×“×“", "×©×©×•×Ÿ ××™×¤×¨× ×©××•×œ×•×‘", "×ª××¨ ×™×”×œ×•××™", "×ª××¨ ×¨×™×™×œ×™"
]

ISRAELI_ARTISTS_SET = set()
for entry in RAW_ISRAELI_ARTISTS:
    # Identify entries like "Adam Ten (××“× ×˜×Ÿ)"
    match = re.search(r"^(.*?)\s*\((.*?)\)$", entry)
    if match:
        ISRAELI_ARTISTS_SET.add(match.group(1).strip().lower())
        ISRAELI_ARTISTS_SET.add(match.group(2).strip().lower())
    else:
        ISRAELI_ARTISTS_SET.add(entry.strip().lower())

EXCLUSION_LIST = [g.lower() for g in ["Drum N Base", "Drum N Bass", "DrumNBase", "Uk Dnb", "Dubstep", "Psytrance"]]

# Pre-process routing dictionary for O(1) case-insensitive lookup
REVERSE_ROUTING = {}
for target, genres in GENRE_ROUTING_DICT.items():
    for g in genres:
        REVERSE_ROUTING[g.lower()] = target

# --- API Helper Functions ---

@st.cache_data(show_spinner=False)
def parse_description(description):
    """Parses description to extract ordered genres and track counts using flexible regex."""
    if not description:
        return []
    
    # 1. Normalize unicode (fraktur/italic letters to ASCII, superscript to numbers)
    text = unicodedata.normalize('NFKC', description)
    
    # 2. Extract just the genre section (usually bounded by | symbols or newlines)
    if '|' in text:
        parts = text.split('|')
        target_part = parts[0]
        # Find the part that looks most like a genre list
        for part in parts:
            if 'â™©' in part or any(str(i) in part for i in range(10)):
                target_part = part
                break
        text = target_part
        
    # 3. Dynamic Regex Extraction
    parsed = []
    # Match words/symbols for genre, followed by optional spaces and then digits
    matches = re.findall(r'([A-Za-z \-\/\,&]+?)\s*([\d]+)', text)
    
    for genre_str, count_str in matches:
        clean_genre = genre_str.strip(', /|â™© ')
        if clean_genre:
            parsed.append({"genre": clean_genre, "count": int(count_str)})
            
    return parsed

def get_all_user_playlists(sp):
    """Fetches ALL user playlists with pagination to bypass 1000+ limits."""
    playlists = []
    offset = 0
    while True:
        results = sp.current_user_playlists(limit=50, offset=offset)
        if not results['items']:
            break
        playlists.extend(results['items'])
        if len(results['items']) < 50:
            break
        offset += len(results['items'])
    return playlists

def get_target_source_playlists(all_playlists):
    """Filters all playlists to find the 97 target source ones (Aum#201-297) and sorts them numerically."""
    pattern = re.compile(r'Aum#(20[1-9]|2[1-8][0-9]|29[0-7])')
    matched = []
    for p in all_playlists:
        if p and p.get('name') and pattern.search(p['name']):
            # Extract number for precise sorting
            num = int(pattern.search(p['name']).group(1))
            matched.append((num, p))
            
    # Sort by the extracted Aum# number
    matched.sort(key=lambda x: x[0])
    return [p for num, p in matched]

def get_all_playlist_tracks(sp, playlist_id):
    """Fetches ALL tracks from a playlist, handling pagination."""
    tracks = []
    offset = 0
    while True:
        results = sp.playlist_items(playlist_id, limit=100, offset=offset)
        if not results['items']:
            break
        tracks.extend(results['items'])
        if len(results['items']) < 100:
            break
        offset += len(results['items'])
    return tracks

def chunk_list(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

def is_israeli_track(track_obj):
    """Determines if a track has Hebrew characters or an Israeli artist."""
    if not track_obj:
        return False
        
    # Check track name for Hebrew characters
    track_name = track_obj.get('name', '')
    if re.search(r'[\u0590-\u05FF]', track_name):
        return True
        
    # Check artists
    artists = track_obj.get('artists', [])
    for artist in artists:
        artist_name = artist.get('name', '')
        if not artist_name:
            continue
            
        # Check artist name for Hebrew characters
        if re.search(r'[\u0590-\u05FF]', artist_name):
            return True
            
        # Check against parsed set 
        if artist_name.strip().lower() in ISRAELI_ARTISTS_SET:
            return True
            
    return False

# --- Streamlit UI & Logic ---

st.set_page_config(page_title="Spotify Playlist Aggregator", page_icon="ğŸ§", layout="wide")

st.title("ğŸ§ Spotify Seasonal Playlist Aggregator")
st.markdown("Automate the routing of tracks from your weekly playlists into 9 seasonal targets based on dynamic description parsing.")

# Authentication Setup via Streamlit Session State
if 'sp' not in st.session_state:
    try:
        scope = "playlist-read-private playlist-read-collaborative playlist-modify-public playlist-modify-private"
        sp_oauth = SpotifyOAuth(scope=scope, open_browser=False, cache_path=".spotifycachesl")
        
        # Check if we already have a token cached
        token_info = sp_oauth.get_cached_token()
        if not token_info:
            # Need to authenticate via URL in Streamlit
            auth_url = sp_oauth.get_authorize_url()
            st.warning("You must authenticate with Spotify first.")
            st.markdown(f"**[Click here to log in to Spotify]({auth_url})**")
            
            auth_code = st.text_input("Enter the Authorization URL you were redirected to:")
            if auth_code:
                try:
                    code = sp_oauth.parse_response_code(auth_code)
                    sp_oauth.get_access_token(code)
                    st.session_state['sp'] = spotipy.Spotify(auth_manager=sp_oauth)
                    st.success("Successfully authenticated!")
                    st.rerun()
                except Exception as e:
                    st.error(f"Authentication failed: {e}")
            st.stop()
        else:
            st.session_state['sp'] = spotipy.Spotify(auth_manager=sp_oauth)
    except Exception as e:
        st.error(f"OAuth initialization failed. Make sure your .env variables are set. Details: {e}")
        st.stop()

sp = st.session_state['sp']

# Caching the heavy initial API calls so the UI doesn't lag on button clicks
@st.cache_data(show_spinner="Fetching 1000+ playlists from Spotify API...")
def load_source_playlists(_sp):
    all_pls = get_all_user_playlists(_sp)
    return get_target_source_playlists(all_pls)

@st.cache_data(show_spinner="Fetching target deduplication data...")
def load_target_existing_uris(_sp):
    existing = {}
    for target_name, target_id in TARGET_PLAYLISTS.items():
        tracks = get_all_playlist_tracks(_sp, target_id)
        uris = set()
        for item in tracks:
            t = item.get('track')
            if t and t.get('uri'):
                uris.add(t['uri'])
        existing[target_name] = uris
    return existing

# Sidebar status
st.sidebar.header("Status")

all_source_playlists = load_source_playlists(sp)
if not all_source_playlists:
    st.error("No source playlists matching `Aum#201-...` found.")
    st.stop()

st.sidebar.success(f"Loaded {len(all_source_playlists)} total Source Playlists.")

# Application State Configuration
st.session_state.setdefault("simulation_done", False)
st.session_state.setdefault("migration_done", False)
st.session_state.setdefault("current_playlist_index", 0)
st.session_state.setdefault("cumulative_audit_log", [])

if 'target_existing_uris' not in st.session_state:
    st.session_state['target_existing_uris'] = load_target_existing_uris(sp)

# 1. Visual Pre-Flight Check
st.subheader("1. Identified Target Source Playlists")
st.markdown("Playlists are correctly sorted chronologically by their `Aum#`.")
with st.expander("View Source Playlists", expanded=False):
    df_sources = pd.DataFrame([{"Aum#": int(re.search(r'Aum#(20[1-9]|2[1-8][0-9]|29[0-7])', p['name']).group(1)), "Name": p['name'], "Tracks": p['tracks']['total'], "Description": p.get('description', '')} for p in all_source_playlists])
    st.dataframe(df_sources, use_container_width=True)

def process_mapping(simulate_only=True, batch_size=2):
    """Core logic to map tracks, handling simulation and execution states for a specific batch slice."""
    
    audit_log = []
    target_staged_tracks = {t: [] for t in TARGET_PLAYLISTS.keys()}
    
    global_anomalies = set()
    total_skipped = 0
    total_dropped = 0
    total_null = 0
    local_existing_uris = {k: set(v) for k,v in st.session_state['target_existing_uris'].items()}

    progress_text = "Simulating Mapping..." if simulate_only else "Executing Batch Migration..."
    progress_bar = st.progress(0, text=progress_text)
    
    start_idx = 0 if simulate_only else st.session_state["current_playlist_index"]
    end_idx = min(start_idx + batch_size, len(all_source_playlists))
    batch_playlists = all_source_playlists[start_idx:end_idx]
    
    if not batch_playlists:
        st.warning("No more playlists left to process.")
        return [], {}, set()
        
    for idx, playlist in enumerate(batch_playlists):
        progress_bar.progress((idx) / len(batch_playlists), text=f"{progress_text} ({idx+1}/{len(batch_playlists)})")
        
        plist_name = playlist['name']
        description = playlist.get('description', '')
        parsed_genres = parse_description(description)
        tracks = get_all_playlist_tracks(sp, playlist['id'])
        
        track_index = 0
        for p_genre in parsed_genres:
            genre_name = p_genre['genre'].lower()
            count = p_genre['count']
            
            target = REVERSE_ROUTING.get(genre_name)
            is_excluded = genre_name in EXCLUSION_LIST
            
            if not target and not is_excluded:
                global_anomalies.add(genre_name)
                
            for _ in range(count):
                if track_index >= len(tracks):
                    break
                
                item = tracks[track_index]
                track_index += 1
                
                track_obj = item.get('track')
                if not track_obj or not track_obj.get('uri') or track_obj['uri'].startswith('spotify:local:'):
                    total_null += 1
                    track_name = track_obj.get('name', 'Unknown') if track_obj else 'Unknown Data'
                    audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": "None", "Track URI": "None", "Track Name": track_name, "Action Taken": "Skipped (Null URI)"})
                    continue
                
                uri = track_obj['uri']
                track_name = track_obj.get('name', 'Unknown')
                
                if is_excluded:
                    total_dropped += 1
                    audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": "Drop List", "Track URI": uri, "Track Name": track_name, "Action Taken": "Dropped (Exclusion List)"})
                    continue
                    
                israeli_bonus_matched = False
                
                if target:
                    if uri in local_existing_uris[target]:
                        total_skipped += 1
                        audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": target, "Track URI": uri, "Track Name": track_name, "Action Taken": "Skipped Duplicate"})
                    else:
                        target_staged_tracks[target].append(uri)
                        local_existing_uris[target].add(uri)
                        audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": target, "Track URI": uri, "Track Name": track_name, "Action Taken": "Appended"})

                # --- Parallel Israeli Music Routing ---
                if target != "Israeli Music" and is_israeli_track(track_obj):
                    israeli_target = "Israeli Music"
                    israeli_bonus_matched = True
                    if uri in local_existing_uris[israeli_target]:
                        audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": israeli_target, "Track URI": uri, "Track Name": track_name, "Action Taken": "Skipped Duplicate (Bonus: Israeli Music)"})
                    else:
                        target_staged_tracks[israeli_target].append(uri)
                        local_existing_uris[israeli_target].add(uri)
                        audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": israeli_target, "Track URI": uri, "Track Name": track_name, "Action Taken": "Appended (Bonus: Israeli Music)"})
                        
                if not target and not israeli_bonus_matched:
                    audit_log.append({"Source Playlist": plist_name, "Parsed Genre": genre_name, "Target Playlist": "None", "Track URI": uri, "Track Name": track_name, "Action Taken": "Unmapped / Ignored"})

    progress_bar.progress(1.0, text="Process Complete!")
    return audit_log, target_staged_tracks, global_anomalies

# 2. Phase A: Simulation
st.subheader("2. Phase A: Dry-Run Simulation")
st.markdown("Run a simulation on exactly 2 playlists to verify mapping integrity before committing database POST operations.")

if st.button("Run Mapping Simulation (Dry-Run)", type="primary"):
    with st.spinner("Processing simulation..."):
        sim_log, staged, anomalies = process_mapping(simulate_only=True, batch_size=2)
        st.session_state['simulation_done'] = True
        
        sim_df = pd.DataFrame(sim_log)
        
        col1, col2, col3 = st.columns(3)
        col1.metric("Tracks Staged", sum(len(v) for v in staged.values()))
        col2.metric("Duplicates Skipped", len(sim_df[sim_df['Action Taken'].str.contains('Skipped Duplicate')]) if not sim_df.empty else 0)
        col3.metric("Unmapped Anomalies", len(anomalies))
        
        st.markdown("**Simulation Audit Log Preview:**")
        st.dataframe(sim_df, use_container_width=True)
        
        if anomalies:
            st.warning(f"Unmapped Genres Detected: {', '.join(anomalies)}")

# 3. Phase B: Execution (Batch Control Panel)
if st.session_state['simulation_done']:
    st.divider()
    st.subheader("3. Phase B: Execute Batch Migration")
    st.markdown(f"**Current Progress:** Processed `{st.session_state['current_playlist_index']}` out of `{len(all_source_playlists)}` playlists.")
    
    remaining = len(all_source_playlists) - st.session_state['current_playlist_index']
    st.progress(st.session_state['current_playlist_index'] / len(all_source_playlists))
    
    if remaining > 0:
        c1, c2, c3 = st.columns(3)
        batch_to_run = 0
        
        if c1.button("Process Next 5 Playlists", disabled=(remaining==0)):
            batch_to_run = min(5, remaining)
        if c2.button("Process Next 10 Playlists", disabled=(remaining==0)):
            batch_to_run = min(10, remaining)
        if c3.button("Process All Remaining", disabled=(remaining==0)):
            batch_to_run = remaining
            
        if batch_to_run > 0:
            batch_log, staged_tracks, full_anomalies = process_mapping(simulate_only=False, batch_size=batch_to_run)
            
            with st.status(f"Uploading Batch ({batch_to_run} playlists)...", expanded=True) as status:
                chunks_done = 0
                for target_name, uris in staged_tracks.items():
                    if not uris:
                        continue
                    target_id = TARGET_PLAYLISTS[target_name]
                    st.write(f"Pushing {len(uris)} new tracks to `{target_name}`...")
                    for chunk in chunk_list(uris, 100):
                        sp.playlist_add_items(target_id, chunk)
                        chunks_done += 1
                        time.sleep(0.5)
                status.update(label="Batch Upload Complete!", state="complete", expanded=False)
            
            # Update cumulative State
            start_num = st.session_state["current_playlist_index"]
            st.session_state["current_playlist_index"] += batch_to_run
            st.session_state["cumulative_audit_log"].extend(batch_log)
            
            # Update local URIs so the next batch knows about the tracks we just appended
            for tgt, uris in staged_tracks.items():
                st.session_state['target_existing_uris'][tgt].update(uris)
                
            st.success(f"Successfully processed playlists index {start_num} through {start_num + batch_to_run - 1}!")
            st.rerun()
    else:
        st.success("All playlists have been completely migrated!")

# 4. Phase C: Cumulative CSV Reporting
st.divider()
st.subheader("4. Cumulative Audit Log")

cumulative_log = st.session_state["cumulative_audit_log"]
if cumulative_log:
    final_df = pd.DataFrame(cumulative_log)
    st.dataframe(final_df.tail(100), use_container_width=True)
    st.caption("Showing last 100 entries of the cumulative run...")
    
    csv = final_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Download Cumulative Audit Log (CSV)",
        data=csv,
        file_name='spotify_migration_audit_log.csv',
        mime='text/csv',
        type="primary"
    )
else:
    st.info("No batches executed yet. The cumulative audit log is empty.")
